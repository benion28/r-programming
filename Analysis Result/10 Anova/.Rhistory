ggplot(prediction_frame, aes(x = SVR_Predictions, y = Real.Values)) +
geom_freqpoly(fill = "blue") +
labs(title = "Species Frequency Distribution Bar", x = "Species", y = "Frequency")
# Model Prediction Histogram
ggplot(prediction_frame, aes(x = SVR_Predictions, y = Real.Values)) +
geom_freqpoly(fill = "blue") +
labs(title = "Species Frequency Distribution Bar", x = "Species", y = "Frequency")
# Model Prediction Histogram
ggplot(prediction_frame, aes(y = SVR_Predictions)) +
geom_freqpoly() +
labs(title = "Species Frequency Distribution Bar", x = "Species", y = "Frequency")
# Model Prediction Histogram
ggplot(prediction_frame, aes(y = SVR_Predictions)) +
geom_freqpoly(bins = 30) +
labs(title = "Species Frequency Distribution Bar", x = "Species", y = "Frequency")
# Model Prediction Histogram
ggplot(prediction_frame, aes(y = SVR_Predictions)) +
geom_histogram(bins = 30) +
labs(title = "Species Frequency Distribution Bar", x = "Species", y = "Frequency")
# Model Prediction Histogram
ggplot(prediction_frame, aes(x = SVR_Predictions)) +
geom_histogram(bins = 30) +
labs(title = "Species Frequency Distribution Bar", x = "Species", y = "Frequency")
prediction_frame
# Model Prediction Histogram
ggplot(prediction_frame, aes(x = SVR_Predictions)) +
geom_histogram(bins = 30, color = "red") +
labs(title = "Species Frequency Distribution Bar", x = "Species", y = "Frequency")
# Model Prediction Histogram
ggplot(prediction_frame, aes(x = SVR_Predictions)) +
geom_histogram(bins = 30, fill = "red") +
labs(title = "Species Frequency Distribution Bar", x = "Species", y = "Frequency")
# Model Prediction Histogram
ggplot(prediction_frame, aes(x = SVR_Predictions)) +
geom_histogram(bins = 30, fill = "pink") +
labs(title = "Species Frequency Distribution Bar", x = "Species", y = "Frequency")
# Model Prediction Histogram
ggplot(prediction_frame, aes(x = SVR_Predictions)) +
geom_histogram(bins = 30, fill = "purple") +
labs(title = "Species Frequency Distribution Bar", x = "Species", y = "Frequency")
# Senna siamea Species Table
ss_plot_no <- dataset$PLOT.NO[dataset$SPECIES == "Senna siamea"]
ss_species <- dataset$SPECIES[dataset$SPECIES == "Senna siamea"]
sl_diameter
# Import data set
dataset <-  read.csv("C:\\Benion\\Benion Programmings\\Python\\AI & ML\\data\\benion-tree-hd-dataset-new.csv", head=TRUE, sep=",")
# Senna siamea Species Table
ss_plot_no <- dataset$PLOT.NO[dataset$SPECIES == "Senna siamea"]
ss_species <- dataset$SPECIES[dataset$SPECIES == "Senna siamea"]
ss_diameter <- dataset$DIAMETER[dataset$SPECIES == "Senna siamea"]
ss_height <- dataset$HEIGHT[dataset$SPECIES == "Senna siamea"]
s_siamea_table <- data.frame("Plot No"=ss_plot_no, "Species"=ss_species, "Diameter"=ss_diameter, "Height"=ss_height)
View(s_siamea_table)
# Frequency
species_frequency <- c()
for (variable in unique_species_dataset$Unique.Species) {
item <- species_frequency
total <- length(dataset$SPECIES[dataset$SPECIES == variable])
species_frequency <- append(item, total)
}
# Frequency Table
frequency_table <- data.frame(
"Species" = species_list,
"Frequency" = species_frequency
)
frequency_table <- rbind(frequency_table, "Total" = c("Total", sum(frequency_table$Frequency)))
View(frequency_table)
# Species
species_list <- c()
for (variable in unique_species_dataset$Unique.Species) {
item <- species_list
species_list <- append(item, variable)
}
# Frequency
species_frequency <- c()
for (variable in unique_species_dataset$Unique.Species) {
item <- species_frequency
total <- length(dataset$SPECIES[dataset$SPECIES == variable])
species_frequency <- append(item, total)
}
# Frequency Table
frequency_table <- data.frame(
"Species" = species_list,
"Frequency" = species_frequency
)
frequency_table <- rbind(frequency_table, "Total" = c("Total", sum(frequency_table$Frequency)))
View(frequency_table)
# Species
species_list <- c()
for (variable in unique_species_dataset$Unique.Species) {
item <- species_list
species_list <- append(item, variable)
}
species_list
unique_species_dataset <- data.frame("Unique Species"=unique(dataset$SPECIES))
View(unique_species_dataset)
unique_species_dataset
# Species
species_list <- c()
for (variable in unique_species_dataset$Unique.Species) {
item <- species_list
species_list <- append(item, variable)
}
# Frequency
species_frequency <- c()
for (variable in unique_species_dataset$Unique.Species) {
item <- species_frequency
total <- length(dataset$SPECIES[dataset$SPECIES == variable])
species_frequency <- append(item, total)
}
# Frequency Table
frequency_table <- data.frame(
"Species" = species_list,
"Frequency" = species_frequency
)
frequency_table <- rbind(frequency_table, "Total" = c("Total", sum(frequency_table$Frequency)))
View(frequency_table)
install.packages("anfis")
install.packages("anfis")
install.packages("anfis")
install.packages("anfis")
install.packages("FuzzyR")
install.packages("frbs")
install.packages("Anfis-package")
# 2 vectors -------
country <- c("italy", "canada", "egypt")
# without quotes
codes <- c(italy=380, canada=124, egypt=818)
# with quotes
codes <- c("italy"=380, "canada"=124, "egypt"=818)
codes
class(codes)
# another method
codes <- c(380, 124, 818)
country <- c("italy", "canada", "egypt")
names(codes) <- country
codes
# sequences
seq(1, 10)
seq(1, 10, 2)
# or we can use
1:10
# sub-setting
codes[2]
codes[c(1, 3)]
codes[1:2]
codes["canada"]
codes[c("egypt", "italy")]
# vector arithmetic
heights <- c(69, 62, 66, 70, 70, 73, 67, 73, 67, 70)
heights * 2.54
heights - 69
# vector coercion
# r will coerce 1 and 3 to characters
w <- c(1, "canada", 3)
w
class(w)
# other functions for coercing data
x <- 1:5
y <- as.character(x)
y
as.numeric(y)
# missing data (NA - Not Available)
t <- c("1", "b", "3")
# by coercion b will be converted to NA
as.numeric(t)
# sorting
# sort -- in increasing order
library(dslabs)
data("murders")
sort(murders$total)
# order -- returns the indices that sorts the vector
s <- c(31, 4, 15, 92, 65)
s
sort(s)
order(s)
index <- order(s)
s[index]
# order the state name by murder total
index <- order(murders$total)
murders$state[index]
murders$abb[index]
# rank -- returns the index in order of the highest value
rank(s)
# summary
data.frame(original=s, sort=sort(s), order=order(s), rank=rank(s))
# max returns the highest value
max(murders$total)
# which.max returns the variable with highest value
i_max <- which.max(murders$total)
murders$state[i_max]
# we can also do the same for the minimum
min(murders$total)
i_min <- which.min(murders$total)
i_min
murders$state[i_min]
# state with the highest population
murders$state[which.max(murders$population)]
# how many people does it have
max(murders$population)
# compute the murder rate for every state
murder_rate <- (murders$total / murders$population) * 100000
murder_rate
# order the states by murder rate
murders$state[order(murder_rate, decreasing = TRUE)]
# sorting data frame
# order the data set base on the population of states (ERROR)
murders[order(population)] |> head()
murders[order(region, rate)]
# orders in accending order
murders %>% arrange(rate) %>% head()
# sorting data tables (ERROR)
library("dplyr")
# orders in accending order
murders %>% arrange(rate) %>% head()
# orders in decending order
murders %>% arrange(desc(rate)) %>% head()
# to see a larger proportion
murders %>% top_n(10, rate)
# sorted by murder rate
murders %>% arrange(desc(rate)) %>% top_n(10)
# Unload Packages
library(pacman)
p_unload(all)
# Clear plots
dev.off()  # But only if there IS a plot
# Clear console
cat("\014")  # ctrl+L
# 3 -- indexing
# use of logical to index vectors
l_index <- murder_rate < 0.71
# 3 -- indexing
# use of logical to index vectors
library(dslabs)
data(murders)
murder_rate <- (murders$total / murders$population) * 100000
l_index <- murder_rate < 0.71
l_index <- murder_rate <= 0.71
l_index
murders$state[l_index]
# count the true(1) or false(0) entries
sum(l_index)
# two logical conditions
TRUE & TRUE
TRUE & FALSE
FALSE & FALSE
# two logical conditions with the vectors
west <- murders$region == "West"
safe <- murder_rate <= 1
ll_index <- safe & west
murders$state[ll_index]
# indexing functions
r <- c(FALSE, TRUE, FALSE, TRUE, TRUE, FALSE)
which(r)
w_index <- which(murders$state == "Massachusetts")
w_index
murder_rate[w_index]
# or we can just use normal indexing
w_index <- murders$state == "Massachusetts"
murder_rate[w_index]
# match -- returns the index needed to access them
m_index <- match(c("New York", "Florida", "Texas"), murders$state)
m_index
murders$state[m_index]
murder_rate[m_index]
# %in% -- to check if the element of the first is in the second
p <- c("a", "b", "c", "d", "e")
q <- c("a", "d", "f")
q %in% p
(c("Boston", "Dakota", "Washington") %in% murders$state)
# Basic data wrangling
library("dplyr")
# add murder rate to our table
murders <- mutate(murders, rate=total/population * 100000)
# only show the entries lower with murder rate than 0.71
filter(murders, rate <= 0.71)
# to select columns we want to work with
new_table <- select(murders, state, region, rate)
filter(new_table, rate <= 0.71)
# we can use pipe to select, filter and insert into table
murders %>% select(state, region, rate) %>% filter(rate <= 0.71)
# Basic plots
# scatter plots
population_in_millions <- murders$population/10^6
total_gun_murders <- murders$total
plot(population_in_millions, total_gun_murders)
# histogram
hist(murders$rate)
murders$state[which.max(murders$rate)]
# boxplot
boxplot(rate ~ region, data = murders)
# summarizing data
library("dplyr")
library("tidyverse")
# access resulting values in the table
# arrange data after sorting
# provide summary statistic into readable code
murders <- mutate(murders, rate=(total / population) * 10^5)
# minimum, median and maximum for states in the western region
ss <- murders %>% filter(region == "West") %>% summarise(
minimum = min(rate),
median = median(rate),
maximum = max(rate)
)
# compute murder rate for the whole country
us_murder_rate <- murders %>% summarize(rate = (sum(total) / sum(population)) * 10^5)
# summarizing data in data table
library(dslabs)
library(data.table)
data(heights)
heights <- setDT(heights)
heights
# summarize
sss <- heights %>% summarize(
average = mean(height),
standard_deviation = sd(height)
)
# alternative of the above
library(data.table)
sss_a <- heights[, .(average = mean(height), standard_deviation = sd(height))]
# computer multiple summary
median_min_max <- function(x) {
qs <- quantile(x, c(0.5, 0, 1))
data.frame(median = qs[1], minimum = qs[2], maximum = qs[3])
}
heights[, .(median_min_max(height))]
# compute summary for different groups
library(data.table)
heights[, .(average = mean(height), standard_deviation = sd(height)), by = sex]
# summarize with more than one value
quantile(x, c(0, 0.5, 1))
# summarize with more than one value
x <- 1:5
quantile(x, c(0, 0.5, 1))
ss <- murders %>% filter(region == "West") %>% summarise(
range = quantile(rate, c(0, 0.5, 1)),
)
# introduction to data.table
library(data.table)
murders[, c("state", "region")] |> head()
murders[, .(state, region)] |> head()    #(Error)
# add new column "rate"
murders[, rate := (total/population) * 100000]   #(Error)
head(murders)
# add new multiple columns
murders[, ":=" (rate = ((total/population) * 100000), rank = rank(population))]   #(Error)
# this not a copy of x, but another name for x
xd <- data.table(a = 1)
yd <- xd
# until x is changed before y becomes another copy and vice versa
# (":=" --- update by reference)
xd[, a := 2]
yd
yd[, a := 1]
xd
# the "copy" forces the copy of the variable
xd <- data.table(a = 1)
yd <- copy(xd)
xd[, a := 2]
yd
# subsetting with "data.table"
# in "dply" we filter like this:
filter(murders, rate <= 0.7)
# then in "data.table"
library(data.table)
murders[rate <= 0.7]  #(ERROR)
# we can combine multiple filter options
murders[rate <= 0.7, .(state, rate)]  #(ERROR)
# compare with the "dplr" approach
library(dplyr)
murders %>% filter(rate <= 0.7) %>% select(state, rate)
# creating data frames
grades <- data.frame(
names = c("John", "Juan", "Jean", "Yao"),
exam_1 = c(95, 80, 90, 85),
exam_2 = c(90, 85, 85, 90)
)
grades
# by default "data.frame" turns characters to "factors"
class(grades$names)
# to prevent this we add an additional option
grades <- data.frame(
names = c("John", "Juan", "Jean", "Yao"),
exam_1 = c(95, 80, 90, 85),
exam_2 = c(90, 85, 85, 90),
stringsAsFactors = FALSE
)
class(grades$names)
# pull access columns
class(us_murder_rate)
# we want access directly to the "rate" column using "pull"
library(dplyr)
us_murder_rate %>% pull(rate)
# we want to save the value directly
us_murder_rate_value <- murders %>%
summarize(rate = (sum(total) / sum(population)) * 10^5) %>%
pull(rate)
us_murder_rate_value
# value is now numeric
class(us_murder_rate_value)
# grouping then summarize
# medium murder rate in each region of the USA
library(dplyr)
murders %>% group_by(region)
# this is now a special data frame called "a grouped" data frame
murders %>% group_by(region) %>% summarize(median = median(rate))
# the dot placeholder
# use of the "." to immitate the "pull"
us_murder_rate_value_d <- murders %>%
summarize(rate = (sum(total) / sum(population)) * 10^5) %>%
.$rate
us_murder_rate_value_d
# value is now numeric
class(us_murder_rate_value_d)
# Unload Packages
library(pacman)
p_unload(all)
# Clear plots
dev.off()  # But only if there IS a plot
# Clear console
cat("\014")  # ctrl+L
# Load Libraries
pacman::p_load(pacman, caTools, ggplot2, psych, tidyverse, Metrics, lmfor, dplyr, nlme)
# Load Libraries
pacman::p_load(pacman, caTools, ggplot2, psych, tidyverse, Metrics, lmfor, dplyr, nlme)
# Load Libraries
pacman::p_load(pacman, caTools, ggplot2, psych, tidyverse, Metrics, lmfor, dplyr, nlme)
# Load Libraries
pacman::p_load(pacman, caTools, ggplot2, psych, tidyverse, Metrics, lmfor, dplyr, nlme)
# Load Libraries
pacman::p_load(pacman, caTools, ggplot2, psych, tidyverse, Metrics, lmfor, dplyr, nlme)
# Load Libraries
pacman::p_load(pacman, ggplot2, tidyverse, dplyr, psych, agricolae, car)
# Set Working Directory
setwd("C://Benion//Benion Programmings//R//Analysis Result//10")
# Import data set
dataset <-  read.csv("full-data-5.csv", head=TRUE, sep=",")
head(dataset, n = 10)
summary(dataset)
describe(dataset)
data_description <- describe(dataset)
#------------------------------ Graphical Representation of Data --------------------------------#
# Box plot  suggests a difference of means
names(dataset)
boxplot(D ~ TRT, data = dataset, ylab = " Seedling diameter", xlab = "Treatments", col = "gray")
boxplot(H ~ TRT, data = dataset, ylab = " Seedling height", xlab = "Treatments", col = "gray")
boxplot(NL ~ TRT, data = dataset, ylab = "Number of leaves", xlab = "Treatments", col = "gray")
#------------------------------ Summary Statistics --------------------------------#
t1 <- dataset %>% filter(TRT == "T1")
t2 <- dataset %>% filter(TRT == "T2")
t3 <- dataset %>% filter(TRT == "T3")
# Diameter
summary_statistic_diameter <- data.frame(
"T1" = c(round(mean(t1$D), 1), round(sd(t1$D), 1), round(min(t1$D), 1), round(max(t1$D), 1)),
"T2" = c(round(mean(t2$D), 1), round(sd(t2$D), 1), round(min(t2$D), 1), round(max(t2$D), 1)),
"T3" = c(round(mean(t3$D), 1), round(sd(t3$D), 1), round(min(t3$D), 1), round(max(t3$D), 1))
)
rownames(summary_statistic_diameter) <- c("Mean", "Standard Deviation", "Minimum", "Maximun")
# Height
summary_statistic_height <- data.frame(
"T1" = c(round(mean(t1$H), 1), round(sd(t1$H), 1), round(min(t1$H), 1), round(max(t1$H), 1)),
"T2" = c(round(mean(t2$H), 1), round(sd(t2$H), 1), round(min(t2$H), 1), round(max(t2$H), 1)),
"T3" = c(round(mean(t3$H), 1), round(sd(t3$H), 1), round(min(t3$H), 1), round(max(t3$H), 1))
)
rownames(summary_statistic_height) <- c("Mean", "Standard Deviation", "Minimum", "Maximun")
# No of Leaves
summary_statistic_no_leaves <- data.frame(
"T1" = c(round(mean(t1$NL), 1), round(sd(t1$NL), 1), min(t1$NL), max(t1$NL)),
"T2" = c(round(mean(t2$NL), 1), round(sd(t2$NL), 1), min(t2$NL), max(t2$NL)),
"T3" = c(round(mean(t3$NL), 1), round(sd(t3$NL), 1), min(t3$NL), max(t3$NL))
)
rownames(summary_statistic_no_leaves) <- c("Mean", "Standard Deviation", "Minimum", "Maximun")
#------------------------------ Shapiro Wilks test MOR --------------------------------#
names(dataset)
shapiro_diameter <- shapiro.test(dataset$D)
shapiro_height <- shapiro.test(dataset$H)
shapiro_no_leaves <- shapiro.test(dataset$NL)
# Shapiro Table
shapiro_table <- data.frame(
"Diameter" = c(shapiro_diameter[["statistic"]][["W"]], shapiro_diameter$p.value),
"Height" = c(shapiro_height[["statistic"]][["W"]], shapiro_height$p.value),
"No.Leaves" = c(shapiro_no_leaves[["statistic"]][["W"]], shapiro_no_leaves$p.value)
)
rownames(shapiro_table) <- c("W.value", "P.value")
#------------------------ Homogeneity of variances ---------------------------#
# Check assumption of homoscedasticity
levene_diameter <- leveneTest(D ~ TRT, data = dataset)
levene_height <- leveneTest(H ~ TRT, data = dataset)
levene_no_leaves <- leveneTest(NL ~ TRT, data = dataset)
#------------------------ Anova test ---------------------------#
anova_diameter <- aov(D ~ TRT, data = dataset)
anova_height <-  aov(H ~ TRT, data = dataset)
anova_no_leaves <- aov(NL ~ TRT, data = dataset)
summary_anova_diameter <- summary(anova_diameter)[[1]]  # SIG DIFF AMONG THE MEANS
summary_anova_height <- summary(anova_height)[[1]]  # NO SIG DIFF AMONG THE MEANS
summary_anova_no_leaves <- summary(anova_no_leaves)[[1]]  # NO SIG DIFF AMONG THE MEANS
#------------------------ Post HOC ---------------------------#
# Tukey multiple comparisons of means
tukey_diameter <- TukeyHSD(anova_diameter)
tukey_diameter_table <- data.frame(tukey_diameter$TRT)
hsd_test <- HSD.test(anova_diameter, "TRT")
hsd_test_means <- data.frame(hsd_test$means)
hsd_test_groups <- data.frame(hsd_test$groups)
summary(anova_height)[[1]][1, 1]
summary(anova_height)[[1]][2, 1]
# F-Critical Value
f_cri_diameter <- qf(1 - 0.05, summary(anova_diameter)[[1]][1, 1], summary(anova_diameter)[[1]][2, 1])
f_cri_height <- qf(1 - 0.05, summary(anova_height)[[1]][1, 1], summary(anova_height)[[1]][2, 1])
f_cri_no_leaves <- qf(1 - 0.05, summary(anova_no_leaves)[[1]][1, 1], summary(anova_no_leaves)[[1]][2, 1])
# F-Critical Value
f_critical <- qf(1 - 0.05, summary(anova_diameter)[[1]][1, 1], summary(anova_diameter)[[1]][2, 1])
f_critical
